package edu.mst.cs206.e;
//import java.io.IOException;

//FIXME Fix the cross evaluation

/**
 * Contains functionality for evaluating rules, calculating fitness, and performing cross validation
 * <br><br>
 * 
 * 
 * @author Edward Norris, Eric Noles
 *
 */
public class Evaluator {
	
	/**
	 * Data Container class - Contains results from cross Validation step bundled together
	 * 
	 * @author etnc6d
	 *
	 */
	public static class DataBundle{
		public double precision;
		public double recall;
		public double fitness;
		public SummaryBin crossValSummary;
		
		/**
		 * Default Constructor - Initalizes all variables to zero
		 */
		public DataBundle(){
			precision = 0;
			recall = 0;
			fitness = 0;
			crossValSummary = null;
		}
	}
	
	
	/**
	 * Default Constructor
	 * <br><br>
	 * No attributes to initialize
	 */
	public Evaluator(){
		
	}


	/**
	 * Determines the fitness of two summaries. One summary should be the base of example and the other should be
	 * the generated summary that will be compared to it. Which is summary1 and which is summary2 should make
	 * no difference.
	 * 
	 * @param summary1
	 * 	The one of the two summaries that will be evaluated
	 * @param summary2
	 * 	The other summary that will be evaluated
	 * @return
	 * 	The fitness of the two summaries
	 */
	public double fitness(SummaryBin summary1, SummaryBin summary2){
		return ((precision(summary1, summary2)+recall(summary1, summary2)) / 2.0);
	}
	
	
	/**
	 * Returns the precision of the two summaries
	 * <br>
	 * Precision: Number of common code element sbetween the manaul and the generated
	 * summaries / number o fcode elements in the manual summary
	 * @param genSummary
	 * 	The summary generated previously by the code
	 * @param baseSummary
	 * 	The base of example summary
	 * @return
	 * 	The precision of the two summaries
	 */
	public double precision(SummaryBin genSummary, SummaryBin baseSummary){
		double numerator=0;
		double fit;
		// For every element in the first summary, cross reference it with every element in
		// the second summary. Count the matches
		for(int i=0; i < genSummary.name.size(); i++){
			for(int j=0; j < baseSummary.name.size(); j++){
				if(genSummary.name.elementAt(i).equals(baseSummary.name.elementAt(j))){ 
//						&& genSummary.isClass.elementAt(i).equals(baseSummary.isClass.elementAt(j))){
					numerator++;
				}
			}
		}
		// The fitness is the matches over the averate size of the two summaries
//		fit = ((numerator/summary1.name.size())+(numerator/summary2.name.size()))/2;
		fit = numerator/baseSummary.name.size();
		return fit;
	}
	
	
	/**
	 * Returns the recall of the two summaries
	 * <br>
	 * Precision: Number of common code element sbetween the manaul and the generated
	 * summaries / number o fcode elements in the generated summary
	 * @param genSummary
	 * 	The summary generated previously by the code
	 * @param baseSummary
	 * 	The base of example summary
	 * @return
	 * 	The recall of the two summaries
	 */
	public double recall(SummaryBin genSummary, SummaryBin baseSummary){
		double numerator=0;
		double fit;
		// For every element in the first summary, cross reference it with every element in
		// the second summary. Count the matches
		for(int i=0; i < genSummary.name.size(); i++){
			for(int j=0; j < baseSummary.name.size(); j++){
				if(genSummary.name.elementAt(i).equals(baseSummary.name.elementAt(j))){
//						&& genSummary.isClass.elementAt(i).equals(baseSummary.isClass.elementAt(j))){
					numerator++;
				}
			}
		}
		// The fitness is the matches over the averate size of the two summaries
//		fit = ((numerator/summary1.name.size())+(numerator/summary2.name.size()))/2;
		fit = numerator/genSummary.name.size();
		return fit;
	}
	
	
	/**
	 * Evaluates a set of rules on a set of metrics, generating a summary. This summary can be used later to 
	 * determine a fitness value
	 * 
	 * @param rules
	 * 	The RuleSet containing the rules that have been generated. These rules will be applied to each metric.
	 * Any metric that passes any single rule will be added to the summary
	 * @param metrics
	 * 	The metrics that will be evaluated. This object represents a list of classes and methods and each of 
	 * their six corresponding  metric values.
	 * @return
	 * 	A summary generated by applying rules to metrics
	 */
	public SummaryBin executeRuleSet(RuleSet rules, MetricBin metrics){
		
		SummaryBin toReturn = new SummaryBin();
		
		// For every metric, for every rule that can evaluate it...
		for(int i = 0; i < metrics.metricValues.size(); i++){
			for(int j = 0; j < rules.numRules; j++){
				// If that metric passes the rule, add it to the summary
				if(executeRule(rules.accessRule(j), metrics, i)){
//						toReturn.isClass.add(metrics.classes.elementAt(i));
						toReturn.name.add(metrics.names.elementAt(i));
						break;
				}
			}
		}
		return toReturn;
	}
	
	
	/**
	 * Evaluates a rule on a single metric to determine whether or not that metric should be added to a
	 * summary. If this function evaluates to false, A later run of the function using a different rule
	 * could still add that metric.
	 * 
	 * @param rule
	 * 	A MetricNode containing the rule that will be evaluated
	 * @param metrics
	 * 	A MetricBin object that contains all classes and methods and all of their corresponding metric values
	 * @param index
	 * 	The index of the metric that will be evaluated. Since an entire MetricBin object is passed, an index that
	 * determines which metric this rule is testing must be passed
	 * @return
	 * 	True if the metric should be added to the summary false otherwise
	 */
	public boolean executeRule(MetricNode rule, MetricBin metrics, int index){
		// Either I'm a leaf or not; If I'm a leaf, Either the threshold is greater than or less than the
		// acutal value, test all cases.
		if(rule.isLeaf){
			if(rule.greaterThan){
				return (metrics.metricValues.elementAt(index)[rule.metricValue] > rule.threshold);
			}else{
				return (metrics.metricValues.elementAt(index)[rule.metricValue] < rule.threshold);
			}
		}else{
			if(rule.opAND){
				return (executeRule(rule.l, metrics, index) && executeRule(rule.r, metrics, index));
			}else{
				return (executeRule(rule.l, metrics, index) || executeRule(rule.r, metrics, index));
			}
		}
	}
	

	/**
	 * Determines the fitness of a provided summary and a second summary that is generated by the funciton.
	 * 
	 * @param baseSummary
	 * 	
	 * @param genSummary
	 * @param genRules
	 * @param secondMetrics
	 * @return
	 */
	
	/**
	 * Generates a new summary using the metrics for system two and the ruleset generated with system 1.
	 * After this is done, the precison, recall, and fitness are all returned as well as the new summary
	 * that was generated
	 * 
	 * @param sys1RuleSet
	 * 	The ruleset that was generated by repeatedly generating new rulesets and comparing their fitness
	 * @param sys2Summary
	 * 	A user generated summary that represents the target summary for the cross validation
	 * @param sys2Metrics
	 * 	The metrics that compose the second system.
	 * @return
	 * 	A DataBundle that contains the precision, recall, fitness and summary generated
	 */
    public DataBundle crossValidation(RuleSet sys1RuleSet, SummaryBin sys2Summary, MetricBin sys2Metrics){
    	
    	DataBundle toReturn = new DataBundle();
    	
    	// Make a new Evaluator and use it to generate a summary
    	Evaluator evalor  = new Evaluator();
    	SummaryBin sys2NewSummary =evalor.executeRuleSet(sys1RuleSet, sys2Metrics);
    	
    	// sys2NewSummary is now the generated summary and sys2Summary which was parsed earlier is acting as
    	// the base of example for this step
    	toReturn.precision = precision(sys2NewSummary, sys2Summary);
    	toReturn.recall = recall(sys2NewSummary, sys2Summary);
    	toReturn.fitness = fitness(sys2NewSummary, sys2Summary);
    	toReturn.crossValSummary = sys2NewSummary;
    	
    	return toReturn;
    }
}
