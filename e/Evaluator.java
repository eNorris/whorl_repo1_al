package edu.mst.cs206.e;
import java.io.IOException;

//FIXME Fix the cross evaluation

/**
 * Contains functionality for evaluating rules, calculating fitness, and performing cross validation
 * <br><br>
 * 
 * 
 * @author etnc6d
 *
 */
public class Evaluator {
	
	/**
	 * Default Constructor
	 * <br><br>
	 * No attributes to initialize
	 */
	public Evaluator(){
		
	}


	/**
	 * Determines the fitness of two summaries. One summary should be the base of example and the other should be
	 * the generated summary that will be compared to it. Which is summary1 and which is summary2 should make
	 * no difference.
	 * 
	 * @param summary1
	 * 	The one of the two summaries that will be evaluated
	 * @param summary2
	 * 	The other summary that will be evaluated
	 * @return
	 * 	The fitness of the two summaries
	 */
	public double fitness(SummaryBin summary1, SummaryBin summary2){
		double numerator=0;
		double fit;
		for(int i=0; i < summary1.name.size(); i++){
			for(int j=0; j < summary2.name.size(); j++){
				if(summary1.name.elementAt(i).equals(summary2.name.elementAt(j)) 
						&& summary1.isClass.elementAt(i).equals(summary2.isClass.elementAt(j))){
					numerator++;
				}
			}
		}
		fit = ((numerator/summary1.name.size())+(numerator/summary2.name.size()))/2;
		return fit;
	}
	
	
	/**
	 * Evaluates a set of rules on a set of metrics, generating a summary. This summary can be used later to 
	 * determine a fitness value
	 * 
	 * @param rules
	 * 	The RuleSet containing the rules that have been generated. These rules will be applied to each metric.
	 * Any metric that passes any single rule will be added to the summary
	 * @param metrics
	 * 	The metrics that will be evaluated. This object represents a list of classes and methods and each of 
	 * their six corresponding  metric values.
	 * @return
	 * 	A summary generated by applying rules to metrics
	 */
	public SummaryBin executeRuleSet(RuleSet rules, MetricBin metrics){
		
		SummaryBin toReturn = new SummaryBin();
		
		// For every metric
		for(int i = 0; i < metrics.metricValues.size(); i++){
			for(int j = 0; j < rules.numRules; j++){
				if(executeRule(rules.accessRule(j), metrics, i)){
						toReturn.isClass.add(metrics.classes.elementAt(i));
						toReturn.name.add(metrics.names.elementAt(i));
						break;
				}
			}
		}
		return toReturn;
	}
	
	
	/**
	 * Evaluates a rule on a single metric to determine whether or not that metric should be added to a
	 * summary. If this function evaluates to false, A later run of the function using a different rule
	 * could still add that metric.
	 * 
	 * @param rule
	 * 	A MetricNode containing the rule that will be evaluated
	 * @param metrics
	 * 	A MetricBin object that contains all classes and methods and all of their corresponding metric values
	 * @param index
	 * 	The index of the metric that will be evaluated. Since an entire MetricBin object is passed, an index that
	 * determines which metric this rule is testing must be passed
	 * @return
	 * 	True if the metric should be added to the summary false otherwise
	 */
	public boolean executeRule(MetricNode rule, MetricBin metrics, int index){
		
		if(rule.isLeaf){
			if(rule.greaterThan){
				return (metrics.metricValues.elementAt(index)[rule.metricValue] > rule.threshold);
			}else{
				return (metrics.metricValues.elementAt(index)[rule.metricValue] < rule.threshold);
			}
		}else{
			if(rule.opAND){
				return (executeRule(rule.l, metrics, index) && executeRule(rule.r, metrics, index));
			}else{
				return (executeRule(rule.l, metrics, index) && executeRule(rule.r, metrics, index));
			}
		}
	}
	
	// takes as input: the final generated summary(genSummary)
	// takes as input: the ruleset used to generate summary 2
	/**
	 * Determines the fitness of a provided summary and a second summary that is generated by the funciton.
	 * 
	 * @param baseSummary
	 * 	
	 * @param genSummary
	 * @param rules
	 * @param baseMetrics
	 * @return
	 */
    double crossValidation(SummaryBin baseSummary, SummaryBin genSummary, RuleSet rules, MetricBin baseMetrics){
    	
    	double fit1, fit2;
    	
    	MetricBin genMetrics = new MetricBin();
//		genMetrics.parseThresholds("Filename2.txt");
    	/*try{
    		genMetrics.parseMetrics("filename.txt");
    	}
		genMetrics.parseMetrics("filename.txt");*/
		
		
		
		try {
			if(!genMetrics.parseMetrics("filename.txt")){
				System.out.print("ERROR: Main::main(): could not parse metrics file");
			}
		} catch (IOException e) {
			System.out.print("Error, could not find file");
			e.printStackTrace();
		}
		
		Evaluator eval = new Evaluator();
		
		// baseSummary is a summary generated with metrics from system2, and the rules used to generate the
    	// 		summary of system 2
    	SummaryBin baseSummary2 = eval.executeRuleSet(rules,baseMetrics); 
    	
    	//the fitness function for the comparison between the base of examples and the generated summary for sys1
    	fit1 = eval.fitness(baseSummary, baseSummary2); 
    	
    	//now we need to generate the best rules for generating the base of examples summary
    	RuleSet testRules = new RuleSet();
		double bestFitness = 0.0;
		RuleSet bestRuleSet = null;
    	
		// code from main that generated the best rules for genSummary. Instead we generate best rules for
		// 		our base of examples summary, using the genSummary as our new base of examples
    	for(int i = 0; i < 1000; i++){
			testRules.generate(5, 0.5, 5);
			SummaryBin newSummary = eval.executeRuleSet(testRules,  genMetrics);
			double fitness = eval.fitness(genSummary,  newSummary);
			
			if(fitness > bestFitness){
				bestFitness = fitness;
				bestRuleSet = testRules;
			}
		}
    	
    	// generates a new summary of the generated summary, using the best rules for generating a summary
    	// 		of system 1, also known as the base of examples system
    	SummaryBin genSummary2 = eval.executeRuleSet(bestRuleSet, genMetrics);
    	
    	// uses the fitness function to compare our origional generated summary, and the summary generated 
    	// 		for system2 
    	fit2 = eval.fitness(genSummary, genSummary2);
    	
    	double avgFit = (fit1 + fit2) / 2;
    	
    	return avgFit;
    	
    }
}
